{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x105267b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import csv\n",
    "import shapely.geometry as geom\n",
    "import fiona\n",
    "import fiona.crs\n",
    "import shapely\n",
    "import rtree\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rdd = sc.textFile('./entr_buffer.csv')\n",
    "# df = pyspark.sql.DataFrame?\n",
    "# df = spark.read.csv('./entr_buffer.csv', header=True)\n",
    "# # df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countLine(partID, records):\n",
    "    import pyproj\n",
    "    import csv\n",
    "    import shapely.geometry as geom\n",
    "    import fiona\n",
    "    import fiona.crs\n",
    "    import shapely\n",
    "    import rtree\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "    import operator\n",
    "    import pandas as pd\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SQLContext\n",
    "\n",
    "    index = rtree.Rtree()\n",
    "    for idx, geometry in enumerate(entr_buf.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "\n",
    "    entr_lines = {}\n",
    "    proj = pyproj.Proj(init='epsg:2263', preserve_units=True)\n",
    "\n",
    "    if partID==0:\n",
    "        records.next()\n",
    "    reader = csv.reader(records)\n",
    "\n",
    "    for row in reader:\n",
    "        if ((float(row[5])!=0) and float(row[9]!=0)):\n",
    "            p = geom.Point(proj(float(row[5]), float(row[6])))\n",
    "            d = geom.Point(proj(float(row[9]), float(row[10])))\n",
    "            p_potential = index.intersection((p.x,p.y,p.x,p.y))\n",
    "            d_potential = index.intersection((d.x,d.y,d.x,d.y))\n",
    "            p_match = None # The first one match, should be the closest one? No!\n",
    "            d_match = None\n",
    "\n",
    "            for p_idx in p_potential:\n",
    "                if entr_buf.geometry[p_idx].contains(p):\n",
    "                    p_match = p_idx # print 'p',p_idx\n",
    "                    p_lines = set(entr_buf.lines[p_idx])\n",
    "                    break\n",
    "\n",
    "            for d_idx in d_potential:\n",
    "                if entr_buf.geometry[d_idx].contains(d):\n",
    "                    d_match = d_idx # print 'd',d_idx\n",
    "                    d_lines = set(entr_buf.lines[d_idx])\n",
    "                    break\n",
    "\n",
    "            if ((p_match and d_match) and (p_match != d_match)):\n",
    "                dirct_lines = tuple(p_lines.intersection(d_lines))\n",
    "                if dirct_lines:\n",
    "                    entr_lines[dirct_lines] = entr_lines.get(dirct_lines, 0)+1\n",
    "    return entr_lines.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "proj = pyproj.Proj(init='epsg:2263', preserve_units=True)\n",
    "\n",
    "entr_points = sqlContext.read.load('../why_yellow_taxi/Data/2016_(May)_New_York_City_Subway_Station_Entrances.json', \\\n",
    "                                format='json', header=True, inferSchema=True).collect()[0].asDict()['features']\n",
    "routes = ['route_'+str(i) for i in range(1,12)]\n",
    "entr_geo = gpd.GeoDataFrame(columns=['geometry', 'lines'])\n",
    "\n",
    "\n",
    "for i in range(len(entr_points)):\n",
    "    entr_coor = entr_points[i].asDict()['geometry'].asDict()['coordinates']\n",
    "    entr_buffer = Point(proj(float(entr_coor[0]), float(entr_coor[1]))).buffer(100)\n",
    "    entr_prop = entr_points[i].asDict()['properties'].asDict()\n",
    "    entr_lines = [entr_prop[r] for r in routes if entr_prop[r]]\n",
    "    entr_geo = entr_geo.append({'geometry':entr_buffer, 'lines':entr_lines}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global entr_buf\n",
    "entr_buf = entr_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper(record):\n",
    "    for key in record[0]:\n",
    "        yield key, record[1]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #sc = SparkContext(appName=\"bigdata_project\")\n",
    "    #taxi_csv = 'hdfs:///user/st1671/data/yellow_tripdata_2016-01.csv'\n",
    "    rdd = sc.textFile('./df_shuffle.csv')\n",
    "    counts = rdd.mapPartitionsWithIndex(countLine).flatMap(mapper).reduceByKey(lambda x,y: x+y).collect()\n",
    "    #counts.saveAsTextFile('/user/st1671/bigdata_proj/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'A', 7),\n",
       " (u'Q', 5),\n",
       " (u'C', 11),\n",
       " (u'E', 7),\n",
       " (u'M', 2),\n",
       " (u'1', 12),\n",
       " (u'3', 2),\n",
       " (u'5', 1),\n",
       " (u'7', 1),\n",
       " (u'B', 1),\n",
       " (u'D', 1),\n",
       " (u'F', 4),\n",
       " (u'L', 3),\n",
       " (u'N', 5),\n",
       " (u'R', 5),\n",
       " (u'4', 1),\n",
       " (u'6', 7),\n",
       " (u'2', 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
