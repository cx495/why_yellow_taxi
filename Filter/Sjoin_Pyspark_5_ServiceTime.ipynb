{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_shuffle.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Day of Week | Index |\n",
    "| ----------- | ----- |\n",
    "| Monday      | 0     |\n",
    "| Tuesday     | 1     |\n",
    "| Wednesday   | 2     |\n",
    "| Thursday    | 3     |\n",
    "| Friday      | 4     |\n",
    "| Saturday    | 5     |\n",
    "| Sunday      | 6     |\n",
    "\n",
    "| Hour                | Index |\n",
    "| ------------------- | ----- |\n",
    "| 00:00:00 - 00:59:59 | 0     |\n",
    "| …                   | …     |\n",
    "| 23:00:00 - 23:59:59 | 23    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x105279b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import csv\n",
    "import shapely.geometry as geom\n",
    "import fiona\n",
    "import fiona.crs\n",
    "import shapely\n",
    "import rtree\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import operator\n",
    "# just for display, not for calculation\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countLine(partID, records):\n",
    "    import pyproj\n",
    "    import csv\n",
    "    import shapely.geometry as geom\n",
    "    import fiona\n",
    "    import fiona.crs\n",
    "    import shapely\n",
    "    import rtree\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "    import operator\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    \n",
    "    shapefile = '../why_yellow_taxi/Buffer/entr_buffer_100_feet_epsg4269_nad83/entr_buffer_100_feet_epsg4269_nad83.shp'\n",
    "    entr_buf = gpd.read_file(shapefile)\n",
    "    entr_buf = entr_buf.to_crs(fiona.crs.from_epsg(2263))\n",
    "    \n",
    "    routes = ['Route_' + str(n) for n in range(1, 12)]\n",
    "    entr2line = []\n",
    "    for i in xrange(len(entr_buf)):\n",
    "        lines = []\n",
    "        for line in list(entr_buf.loc[:,routes].ix[i].dropna().values):\n",
    "            try:\n",
    "                line = str(int(line))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            lines.append(line)\n",
    "        entr2line.append(lines)\n",
    "    entr_buf['entr2line'] = entr2line\n",
    "    \n",
    "    index = rtree.Rtree()\n",
    "    for idx, geometry in enumerate(entr_buf.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    \n",
    "\n",
    "    entr_pair = {}\n",
    "    pick_entr = {}\n",
    "    drop_entr = {}\n",
    "    entr_lines = {}\n",
    "    \n",
    "    proj = pyproj.Proj(init='epsg:2263', preserve_units=True)\n",
    "    \n",
    "    if partID==0:\n",
    "        records.next()\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        if ((float(row[5])!=0) and float(row[9]!=0)):\n",
    "            if row[1]:\n",
    "                wd_h = datetime.datetime.strptime(row[1], '%Y-%m-%d %H:%M:%S')\n",
    "                wd = wd_h.weekday()\n",
    "                hour = wd_h.hour\n",
    "            else:\n",
    "                wd = None\n",
    "                hour = None\n",
    "    \n",
    "            p = geom.Point(proj(float(row[5]), float(row[6])))\n",
    "            d = geom.Point(proj(float(row[9]), float(row[10])))\n",
    "            p_potential = index.intersection((p.x,p.y,p.x,p.y))\n",
    "            d_potential = index.intersection((d.x,d.y,d.x,d.y))\n",
    "            p_match = None # The first one match, should be the closest one? No!\n",
    "            d_match = None\n",
    "            \n",
    "            for p_idx in p_potential:\n",
    "                if entr_buf.geometry[p_idx].contains(p):\n",
    "                    p_match = p_idx # print 'p',p_idx\n",
    "                    p_lines = set(entr_buf.entr2line[p_idx])\n",
    "                    break\n",
    "            pick_entr[p_match] = pick_entr.get(p_match, 0)+1\n",
    "            \n",
    "            for d_idx in d_potential:\n",
    "                if entr_buf.geometry[d_idx].contains(d):\n",
    "                    d_match = d_idx # print 'd',d_idx\n",
    "                    d_lines = set(entr_buf.entr2line[d_idx])\n",
    "                    break\n",
    "            drop_entr[d_match] = drop_entr.get(d_match, 0)+1\n",
    "            \n",
    "            if ((p_match and d_match) and (p_match != d_match)):\n",
    "                dirct_lines = tuple(p_lines.intersection(d_lines))\n",
    "                dirct_lines_wd_h = (dirct_lines, wd, hour)\n",
    "                if dirct_lines:\n",
    "                    entr_lines[dirct_lines_wd_h] = entr_lines.get(dirct_lines_wd_h, 0)+1\n",
    "                if p_match > d_match:\n",
    "                    pair = (d_match, p_match)\n",
    "                else:\n",
    "                    pair = (p_match, d_match)\n",
    "                entr_pair[pair] = entr_pair.get(pair, 0)+1\n",
    "                \n",
    "    return entr_lines.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ((Line, DayOfWeek, Hour), Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midnight -> 00:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper(record):\n",
    "    for key in record[0][0]:\n",
    "        yield (key, record[0][1], record[0][2]), record[1]\n",
    "        \n",
    "def service(record):\n",
    "    if (record[0][0] == 'B' and (record[0][1] in [5, 6])):\n",
    "        pass\n",
    "    elif (record[0][0] == 'W' and (record[0][1] in [5, 6])):\n",
    "        pass\n",
    "    elif (record[0][0] == 'C' and (record[0][2] in range(0,6))):\n",
    "        pass\n",
    "    elif (record[0][0] == 'B' and (record[0][1] in range(0,6))):\n",
    "        pass\n",
    "    elif (record[0][0] == 'S' and (record[0][1] in range(0,6))):\n",
    "        pass\n",
    "    elif (record[0][0] == 'W' and (record[0][1] in range(0,6))):\n",
    "        pass\n",
    "    else:\n",
    "        return record\n",
    "        \n",
    "rdd = sc.textFile('./df_shuffle.csv')\n",
    "counts = rdd.mapPartitionsWithIndex(countLine).flatMap(mapper). \\\n",
    "             reduceByKey(lambda x,y: x+y). \\\n",
    "             filter(service). \\\n",
    "             collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('6', 5, 11), 2),\n",
       " (('1', 1, 13), 2),\n",
       " (('2', 1, 13), 1),\n",
       " (('3', 5, 20), 1),\n",
       " ((u'E', 3, 10), 1),\n",
       " (('1', 4, 17), 1),\n",
       " (('2', 4, 6), 1),\n",
       " ((u'M', 5, 8), 1),\n",
       " ((u'C', 5, 20), 1),\n",
       " ((u'A', 4, 17), 1),\n",
       " ((u'F', 1, 21), 1),\n",
       " ((u'L', 2, 20), 1),\n",
       " (('2', 1, 9), 1),\n",
       " (('1', 5, 20), 1),\n",
       " ((u'E', 5, 20), 1),\n",
       " ((u'N', 0, 18), 1),\n",
       " ((u'E', 5, 8), 1),\n",
       " ((u'C', 3, 10), 1),\n",
       " (('1', 3, 14), 1),\n",
       " (('1', 5, 2), 1),\n",
       " ((u'C', 1, 10), 1),\n",
       " ((u'C', 4, 17), 1),\n",
       " ((u'R', 0, 18), 1),\n",
       " ((u'A', 3, 10), 1),\n",
       " ((u'Q', 6, 19), 1),\n",
       " (('6', 0, 16), 1),\n",
       " (('6', 3, 21), 1),\n",
       " ((u'Q', 0, 15), 1),\n",
       " ((u'N', 0, 16), 1),\n",
       " (('4', 0, 16), 1),\n",
       " ((u'R', 0, 16), 1),\n",
       " ((u'E', 1, 10), 1),\n",
       " ((u'F', 4, 14), 1),\n",
       " (('1', 0, 19), 1),\n",
       " (('2', 5, 17), 1),\n",
       " ((u'A', 5, 2), 1),\n",
       " (('1', 3, 16), 1),\n",
       " (('1', 4, 3), 1),\n",
       " (('3', 3, 14), 1),\n",
       " ((u'L', 0, 20), 1),\n",
       " ((u'Q', 6, 21), 1),\n",
       " ((u'C', 2, 15), 1),\n",
       " (('2', 5, 20), 1),\n",
       " (('7', 4, 8), 1),\n",
       " (('6', 0, 13), 1),\n",
       " (('2', 3, 14), 1),\n",
       " (('1', 4, 6), 1),\n",
       " ((u'N', 0, 15), 1),\n",
       " (('1', 0, 12), 1),\n",
       " ((u'E', 6, 6), 1),\n",
       " ((u'E', 5, 19), 1),\n",
       " ((u'L', 4, 11), 1),\n",
       " ((u'F', 4, 7), 1),\n",
       " (('1', 5, 21), 1),\n",
       " ((u'N', 6, 21), 1),\n",
       " (('1', 3, 11), 1),\n",
       " ((u'R', 6, 21), 1),\n",
       " (('1', 5, 23), 1),\n",
       " ((u'C', 5, 13), 1),\n",
       " ((u'R', 6, 19), 1),\n",
       " ((u'A', 5, 19), 1),\n",
       " ((u'A', 1, 9), 1),\n",
       " (('1', 5, 17), 1),\n",
       " (('3', 1, 9), 1),\n",
       " ((u'Q', 0, 18), 1),\n",
       " (('6', 5, 14), 1),\n",
       " ((u'C', 5, 19), 1),\n",
       " ((u'A', 6, 6), 1),\n",
       " ((u'R', 0, 15), 1),\n",
       " (('5', 0, 16), 1),\n",
       " (('1', 6, 22), 1),\n",
       " ((u'F', 5, 14), 1),\n",
       " ((u'Q', 0, 16), 1),\n",
       " (('6', 2, 13), 1),\n",
       " ((u'A', 5, 13), 1),\n",
       " (('3', 4, 6), 1),\n",
       " ((u'M', 6, 14), 1),\n",
       " ((u'D', 5, 2), 1),\n",
       " ((u'C', 6, 6), 1),\n",
       " (('3', 1, 13), 1),\n",
       " (('3', 5, 17), 1),\n",
       " (('1', 0, 14), 1),\n",
       " ((u'C', 1, 9), 1),\n",
       " (('7', 2, 20), 1),\n",
       " ((u'N', 6, 19), 1),\n",
       " (('1', 3, 5), 1),\n",
       " ((u'E', 5, 13), 1),\n",
       " ((u'C', 1, 21), 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t.collect(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t = counts.filter(lambda x: not ((x[0][0] == '6') and (x[0][1] in [5,6]))). \\\n",
    "#             filter(lambda x: not ((x[0][0] == '1') and (x[0][1] in [5,6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(len(counts)):\n",
    "#     if counts[i][0][0] == '6':\n",
    "#         print 'Day of week:{} ; Hour:{}, Counts:{}'.format(counts[i][0][1], counts[i][0][2], counts[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# counts_all = 0\n",
    "# for i in range(len(counts)):\n",
    "#     if (counts[i][0][0] == '6' and counts[i][0][2] == 13):  # Line 6, 13:00-14:00\n",
    "#         counts_all += counts[i][1]\n",
    "#         print 'Day of week:{} ; Hour:{}, Counts:{}'.format(counts[i][0][1], counts[i][0][2], counts[i][1])\n",
    "# print \"Line:{}, Hour:{} - Counts:{}\".format('6', '13', counts_all)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
