{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_shuffle.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Day of Week | Index |\n",
    "| ----------- | ----- |\n",
    "| Monday      | 0     |\n",
    "| Tuesday     | 1     |\n",
    "| Wednesday   | 2     |\n",
    "| Thursday    | 3     |\n",
    "| Friday      | 4     |\n",
    "| Saturday    | 5     |\n",
    "| Sunday      | 6     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x105268b90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import csv\n",
    "import shapely.geometry as geom\n",
    "import fiona\n",
    "import fiona.crs\n",
    "import shapely\n",
    "import rtree\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import operator\n",
    "# just for display, not for calculation\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./df_shuffle.csv')\n",
    "# df.head(10)\n",
    "\n",
    "# def wkd(time):\n",
    "#     return datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S').weekday()\n",
    "\n",
    "# wkd(df.tpep_pickup_datetime[0])\n",
    "# pd.to_datetime(df.tpep_pickup_datetime).map(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countLine(partID, records):\n",
    "    import pyproj\n",
    "    import csv\n",
    "    import shapely.geometry as geom\n",
    "    import fiona\n",
    "    import fiona.crs\n",
    "    import shapely\n",
    "    import rtree\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "    import operator\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    \n",
    "    shapefile = '../why_yellow_taxi/Buffer/entr_buffer_100_feet_epsg4269_nad83/entr_buffer_100_feet_epsg4269_nad83.shp'\n",
    "    entr_buf = gpd.read_file(shapefile)\n",
    "    entr_buf = entr_buf.to_crs(fiona.crs.from_epsg(2263))\n",
    "    \n",
    "    routes = ['Route_' + str(n) for n in range(1, 12)]\n",
    "    entr2line = []\n",
    "    for i in xrange(len(entr_buf)):\n",
    "        lines = []\n",
    "        for line in list(entr_buf.loc[:,routes].ix[i].dropna().values):\n",
    "            try:\n",
    "                line = str(int(line))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            lines.append(line)\n",
    "        entr2line.append(lines)\n",
    "    entr_buf['entr2line'] = entr2line\n",
    "    \n",
    "    index = rtree.Rtree()\n",
    "    for idx, geometry in enumerate(entr_buf.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    \n",
    "\n",
    "    entr_pair = {}\n",
    "    pick_entr = {}\n",
    "    drop_entr = {}\n",
    "    entr_lines = {}\n",
    "    \n",
    "    proj = pyproj.Proj(init='epsg:2263', preserve_units=True)\n",
    "    \n",
    "    if partID==0:\n",
    "        records.next()\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        if ((float(row[5])!=0) and float(row[9]!=0)):\n",
    "            if row[1]:\n",
    "                wd = datetime.datetime.strptime(row[1], '%Y-%m-%d %H:%M:%S').weekday()\n",
    "            else:\n",
    "                wd = None\n",
    "    \n",
    "            p = geom.Point(proj(float(row[5]), float(row[6])))\n",
    "            d = geom.Point(proj(float(row[9]), float(row[10])))\n",
    "            p_potential = index.intersection((p.x,p.y,p.x,p.y))\n",
    "            d_potential = index.intersection((d.x,d.y,d.x,d.y))\n",
    "            p_match = None # The first one match, should be the closest one? No!\n",
    "            d_match = None\n",
    "            \n",
    "            for p_idx in p_potential:\n",
    "                if entr_buf.geometry[p_idx].contains(p):\n",
    "                    p_match = p_idx # print 'p',p_idx\n",
    "                    p_lines = set(entr_buf.entr2line[p_idx])\n",
    "                    break\n",
    "            pick_entr[p_match] = pick_entr.get(p_match, 0)+1\n",
    "            \n",
    "            for d_idx in d_potential:\n",
    "                if entr_buf.geometry[d_idx].contains(d):\n",
    "                    d_match = d_idx # print 'd',d_idx\n",
    "                    d_lines = set(entr_buf.entr2line[d_idx])\n",
    "                    break\n",
    "            drop_entr[d_match] = drop_entr.get(d_match, 0)+1\n",
    "            \n",
    "            if ((p_match and d_match) and (p_match != d_match)):\n",
    "                dirct_lines = tuple(p_lines.intersection(d_lines))\n",
    "                dirct_lines_wd = (dirct_lines, wd)\n",
    "                if dirct_lines:\n",
    "                    #entr_lines[dirct_lines] = entr_lines.get(dirct_lines, 0)+1\n",
    "                    entr_lines[dirct_lines_wd] = entr_lines.get(dirct_lines_wd, 0)+1\n",
    "                if p_match > d_match:\n",
    "                    pair = (d_match, p_match)\n",
    "                else:\n",
    "                    pair = (p_match, d_match)\n",
    "                entr_pair[pair] = entr_pair.get(pair, 0)+1\n",
    "                \n",
    "    return entr_lines.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper(record):\n",
    "    for key in record[0][0]:\n",
    "        yield (key, record[0][1]), record[1]\n",
    "        \n",
    "rdd = sc.textFile('./df_shuffle.csv')\n",
    "counts = rdd.mapPartitionsWithIndex(countLine).flatMap(mapper).reduceByKey(lambda x,y: x+y).collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of week:5 ; Counts:3\n",
      "Day of week:3 ; Counts:1\n",
      "Day of week:0 ; Counts:2\n",
      "Day of week:2 ; Counts:1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(counts)):\n",
    "    if counts[i][0][0] == '6':\n",
    "        print 'Day of week:{} ; Counts:{}'.format(counts[i][0][1], counts[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1', 5), 5),\n",
       " (('1', 3), 4),\n",
       " ((u'E', 5), 4),\n",
       " ((u'C', 5), 4),\n",
       " (('6', 5), 3),\n",
       " (('1', 0), 3),\n",
       " (('1', 4), 3),\n",
       " ((u'Q', 0), 3),\n",
       " ((u'A', 5), 3),\n",
       " ((u'C', 1), 3),\n",
       " ((u'R', 0), 3),\n",
       " ((u'N', 0), 3),\n",
       " (('2', 5), 2),\n",
       " (('2', 1), 2),\n",
       " ((u'Q', 6), 2),\n",
       " ((u'R', 6), 2),\n",
       " (('6', 0), 2),\n",
       " (('1', 1), 2),\n",
       " ((u'F', 4), 2),\n",
       " ((u'N', 6), 2),\n",
       " (('3', 1), 2),\n",
       " (('3', 5), 2),\n",
       " ((u'F', 1), 1),\n",
       " ((u'C', 6), 1),\n",
       " ((u'F', 5), 1),\n",
       " ((u'B', 5), 1),\n",
       " (('1', 6), 1),\n",
       " ((u'E', 6), 1),\n",
       " (('6', 3), 1),\n",
       " (('3', 4), 1),\n",
       " ((u'A', 6), 1),\n",
       " ((u'C', 4), 1),\n",
       " (('7', 2), 1),\n",
       " ((u'A', 4), 1),\n",
       " (('5', 0), 1),\n",
       " (('2', 3), 1),\n",
       " ((u'D', 5), 1),\n",
       " ((u'M', 6), 1),\n",
       " (('7', 4), 1),\n",
       " ((u'C', 2), 1),\n",
       " (('3', 3), 1),\n",
       " ((u'A', 1), 1),\n",
       " (('2', 4), 1),\n",
       " ((u'E', 3), 1),\n",
       " ((u'L', 4), 1),\n",
       " (('6', 2), 1),\n",
       " ((u'M', 5), 1),\n",
       " ((u'A', 3), 1),\n",
       " (('4', 0), 1),\n",
       " ((u'L', 0), 1),\n",
       " ((u'C', 3), 1),\n",
       " ((u'L', 2), 1),\n",
       " ((u'E', 1), 1)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counts, key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
